{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL to NL to SQL architecture. \n",
    "\n",
    "In many cases, a company has already many anlytic assets such like SQLs, procedure, OLAP cubes and others in their firm. \n",
    "\n",
    "SQL is a valuable tool, but it can be challenging to use in a reusable way because it is not always clear what the query is doing.\n",
    "\n",
    "For example, \n",
    "\n",
    "If someone want to know 'which department has poor performace than the average ?'\n",
    "\n",
    "The goal is very simple, but its implementation SQL is very complex. \n",
    "\n",
    "There is a chasm between the business goal and the specific SQL implentation. \n",
    "\n",
    "In this case, pre-defined complex SQL can help to solve this problem. And we should suggest how to retrieve appropriate SQL from the lots of pre-defined SQLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implment this function\n",
    "import pandas as pd\n",
    "\n",
    "def crawl_prefined_sqls():\n",
    "  sqls = []\n",
    "  # goal = \"SQL to check the delay time(second) before shipping for each order and product\"\n",
    "  sqls.append(\"\"\"\n",
    "CREATE TEMP FUNCTION convertIntervalToSecond(start_ts TIMESTAMP, end_ts TIMESTAMP)\n",
    "RETURNS INT64\n",
    "AS (\n",
    "  (EXTRACT(DAY FROM (end_ts - start_ts)) * 86400 +\n",
    "  EXTRACT(HOUR FROM (end_ts - start_ts)) * 3600 +\n",
    "  EXTRACT(MINUTE FROM (end_ts - start_ts)) * 60 +\n",
    "  EXTRACT(SECOND FROM (end_ts - start_ts)))\n",
    ");\n",
    "select convertIntervalToSecond(a.created_at, a.shipped_at) as order_pending_second, \n",
    "  convertIntervalToSecond(b.created_at, b.shipped_at) as product_pending_second, \n",
    "  a.status, a.order_id, a.user_id, a.gender, a.created_at, a.shipped_at, \n",
    "  b.product_id, b.created_at, b.shipped_at, b.delivered_at, b.returned_at\n",
    " from `bigquery-public-data.thelook_ecommerce.orders` a\n",
    " join `bigquery-public-data.thelook_ecommerce.order_items` b on (a.order_id = b.order_id)\n",
    " where a.status not in ('Cancelled') \n",
    "   and a.created_at between '2022-01-01' and '2022-06-30'\n",
    "order by a.order_id, b.product_id\n",
    "  \"\"\")\n",
    "  return sqls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from langchain.chat_models import ChatVertexAI\n",
    "from langchain.llms import VertexAI\n",
    "import os\n",
    "\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")  # @param {type:\"string\"}\n",
    "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
    "\n",
    "llm_vertex = VertexAI(\n",
    "    #model_name=\"text-bison@latest\",\n",
    "    model_name=\"text-bison-32k\",\n",
    "    max_output_tokens=8000,\n",
    "    temperature=0,\n",
    "    top_p=0.8,\n",
    "    top_k=40,\n",
    ")\n",
    "\n",
    "llm = llm_vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_json_response(llm_json_response) -> any:\n",
    "  #print('llm response:'+ response)\n",
    "  start_char = '['\n",
    "  end_char = ']'\n",
    "  if llm_json_response.find('[') == -1 or llm_json_response.find('{') < llm_json_response.find('[') :\n",
    "    start_char = '{'\n",
    "    end_char = '}'\n",
    "  start_index = llm_json_response.find(start_char)\n",
    "  end_index = llm_json_response.rfind(end_char)\n",
    "  json_data = llm_json_response[start_index:end_index+1]\n",
    "  parsed_json = json.loads(json_data)\n",
    "  return parsed_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def explain_sql(sql):\n",
    "  example_json = \"\"\"\n",
    "  {\n",
    "    \"business goal\": \"explanation of the SQL\",\n",
    "    \"prepared sql\": \"select convertIntervalToSecond(a.created_at, a.shipped_at) as order_pending_second from sample_table where created_at between ? and ?\",\n",
    "    \"filters\": [\n",
    "      {\n",
    "        \"column\": \"created_at\",\n",
    "        \"business goal\": \"filter by order created date\",\n",
    "        \"operator\": \"between\",\n",
    "        \"mandatory\": true,\n",
    "        \"type\" : \"TIMESTAMP\",\n",
    "        \"filter names\": [\"order_created_at_start\",\"order_created_at_end\"]\n",
    "      }\n",
    "    ],\n",
    "  }\n",
    "  \"\"\"\n",
    "  prompt_template = \"\"\"You are a serverside developer. \n",
    "  Please convert SQL to prepared statement and extract filters from the SQL in a JSON format.\n",
    "\n",
    "  output format json:\n",
    "  {example_json}\n",
    "\n",
    "  ----------------------------\n",
    "\n",
    "  target sql:\n",
    "  {sql}\n",
    "  \"\"\"\n",
    "  prompt = prompt_template.format(sql=sql, example_json=example_json)\n",
    "  response = llm.predict(prompt)\n",
    "  print(response)\n",
    "  return parse_json_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ```python\n",
      "{\n",
      "    \"business goal\": \"This SQL query calculates the order pending time and product pending time for each order, and then joins the order table with the order items table to get the order details. Finally, it filters the results by order status and created date.\",\n",
      "    \"prepared sql\": \"CREATE TEMP FUNCTION convertIntervalToSecond(start_ts TIMESTAMP, end_ts TIMESTAMP)\\nRETURNS INT64\\nAS (\\n  (EXTRACT(DAY FROM (end_ts - start_ts)) * 86400 +\\n  EXTRACT(HOUR FROM (end_ts - start_ts)) * 3600 +\\n  EXTRACT(MINUTE FROM (end_ts - start_ts)) * 60 +\\n  EXTRACT(SECOND FROM (end_ts - start_ts)))\\n);\\nselect convertIntervalToSecond(a.created_at, a.shipped_at) as order_pending_second, \\n  convertIntervalToSecond(b.created_at, b.shipped_at) as product_pending_second, \\n  a.status, a.order_id, a.user_id, a.gender, a.created_at, a.shipped_at, \\n  b.product_id, b.created_at, b.shipped_at, b.delivered_at, b.returned_at\\n from `bigquery-public-data.thelook_ecommerce.orders` a\\n join `bigquery-public-data.thelook_ecommerce.order_items` b on (a.order_id = b.order_id)\\n where a.status not in (?) \\n   and a.created_at between ? and ?\\norder by a.order_id, b.product_id\",\n",
      "    \"filters\": [\n",
      "      {\n",
      "        \"column\": \"status\",\n",
      "        \"business goal\": \"Filter by order status\",\n",
      "        \"operator\": \"not in\",\n",
      "        \"mandatory\": true,\n",
      "        \"type\": \"STRING\",\n",
      "        \"filter names\": [\"order_status\"]\n",
      "      },\n",
      "      {\n",
      "        \"column\": \"created_at\",\n",
      "        \"business goal\": \"Filter by order created date\",\n",
      "        \"operator\": \"between\",\n",
      "        \"mandatory\": true,\n",
      "        \"type\": \"TIMESTAMP\",\n",
      "        \"filter names\": [\"order_created_at_start\", \"order_created_at_end\"]\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "assetized_queries = []\n",
    "\n",
    "for sql in crawl_prefined_sqls():\n",
    "  assetized_queries.append(explain_sql(sql))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vector_util import VectorDatabase\n",
    "\n",
    "vdb = VectorDatabase()\n",
    "\n",
    "vdb.truncate_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "\n",
    "embeddings = VertexAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_goal_to_vdb(assetized_queries):\n",
    "  for assetized_query in assetized_queries:\n",
    "    description = assetized_query['business goal']\n",
    "    sql = assetized_query['prepared sql']\n",
    "    parameters = assetized_query['filters']\n",
    "    desc_vector = embeddings.embed_query(description)\n",
    "    vdb.insert_record(sql=sql, parameters=parameters, description=description, explore_view=None, model_name=None, table_name=None, column_schema=None, desc_vector=desc_vector)\n",
    "\n",
    "write_goal_to_vdb(assetized_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_query(question):\n",
    "  test_embedding =  embeddings.embed_query(question)\n",
    "  results = []\n",
    "  with vdb.get_connection() as conn:\n",
    "    try:\n",
    "      with conn.cursor() as cur:\n",
    "        select_record = (str(test_embedding).replace(' ',''),)\n",
    "        cur.execute(f\"SELECT sql, parameters, description FROM rag_test where (1 - (desc_vector <=> %s)) > 0.6 limit 1\", select_record)\n",
    "        results = cur.fetchall()\n",
    "        print(results)\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "  return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CREATE TEMP FUNCTION convertIntervalToSecond(start_ts TIMESTAMP, end_ts TIMESTAMP)\\nRETURNS INT64\\nAS (\\n  (EXTRACT(DAY FROM (end_ts - start_ts)) * 86400 +\\n  EXTRACT(HOUR FROM (end_ts - start_ts)) * 3600 +\\n  EXTRACT(MINUTE FROM (end_ts - start_ts)) * 60 +\\n  EXTRACT(SECOND FROM (end_ts - start_ts)))\\n);\\nselect convertIntervalToSecond(a.created_at, a.shipped_at) as order_pending_second, \\n  convertIntervalToSecond(b.created_at, b.shipped_at) as product_pending_second, \\n  a.status, a.order_id, a.user_id, a.gender, a.created_at, a.shipped_at, \\n  b.product_id, b.created_at, b.shipped_at, b.delivered_at, b.returned_at\\n from `bigquery-public-data.thelook_ecommerce.orders` a\\n join `bigquery-public-data.thelook_ecommerce.order_items` b on (a.order_id = b.order_id)\\n where a.status not in (?) \\n   and a.created_at between ? and ?\\norder by a.order_id, b.product_id', \"[{'column': 'status', 'business goal': 'Filter by order status', 'operator': 'not in', 'mandatory': True, 'type': 'STRING', 'filter names': ['order_status']}, {'column': 'created_at', 'business goal': 'Filter by order created date', 'operator': 'between', 'mandatory': True, 'type': 'TIMESTAMP', 'filter names': ['order_created_at_start', 'order_created_at_end']}]\", 'This SQL query calculates the order pending time and product pending time for each order, and then joins the order table with the order items table to get the order details. Finally, it filters the results by order status and created date.')]\n",
      "('CREATE TEMP FUNCTION convertIntervalToSecond(start_ts TIMESTAMP, end_ts TIMESTAMP)\\nRETURNS INT64\\nAS (\\n  (EXTRACT(DAY FROM (end_ts - start_ts)) * 86400 +\\n  EXTRACT(HOUR FROM (end_ts - start_ts)) * 3600 +\\n  EXTRACT(MINUTE FROM (end_ts - start_ts)) * 60 +\\n  EXTRACT(SECOND FROM (end_ts - start_ts)))\\n);\\nselect convertIntervalToSecond(a.created_at, a.shipped_at) as order_pending_second, \\n  convertIntervalToSecond(b.created_at, b.shipped_at) as product_pending_second, \\n  a.status, a.order_id, a.user_id, a.gender, a.created_at, a.shipped_at, \\n  b.product_id, b.created_at, b.shipped_at, b.delivered_at, b.returned_at\\n from `bigquery-public-data.thelook_ecommerce.orders` a\\n join `bigquery-public-data.thelook_ecommerce.order_items` b on (a.order_id = b.order_id)\\n where a.status not in (?) \\n   and a.created_at between ? and ?\\norder by a.order_id, b.product_id', \"[{'column': 'status', 'business goal': 'Filter by order status', 'operator': 'not in', 'mandatory': True, 'type': 'STRING', 'filter names': ['order_status']}, {'column': 'created_at', 'business goal': 'Filter by order created date', 'operator': 'between', 'mandatory': True, 'type': 'TIMESTAMP', 'filter names': ['order_created_at_start', 'order_created_at_end']}]\", 'This SQL query calculates the order pending time and product pending time for each order, and then joins the order table with the order items table to get the order details. Finally, it filters the results by order status and created date.')\n"
     ]
    }
   ],
   "source": [
    "question = \"How to check the delay time(second) before shipping for each order and product?\"\n",
    "\n",
    "assetized_query = get_related_query(question)[0]\n",
    "print(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_filter_values(assetized_query, question):\n",
    "  example_json = \"\"\"\n",
    "  {\n",
    "    \"parameters\": [\n",
    "      {\n",
    "        \"table_name\": \"sample_table\",\n",
    "        \"column\": \"col_1\",\n",
    "        \"operator\" : \"in\", \n",
    "        \"type\" : \"STRING\",\n",
    "        \"filter_names\": [\"col_1_filter\"],\n",
    "        \"extracted_values\": [null]\n",
    "      },\n",
    "      {\n",
    "        \"table_name\": \"sample_table\",\n",
    "        \"column\": \"col_2\",\n",
    "        \"operator\" : \"=\", \n",
    "        \"type\" : \"STRING\",\n",
    "        \"filter_names\": [\"col_2_filter\"],\n",
    "        \"extracted_values\": [\"2022-01\"]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "  \"\"\"\n",
    "\n",
    "  prompt_template = \"\"\"You are a serverside developer. Extract filter values from the question and sql. If you can't find filter values from the question, check whether there is any missing filter values in the question. Do not suggest codes. Output should be the following JSON format.\n",
    "\n",
    "  output format json:\n",
    "  {example_json}\n",
    "\n",
    "  ----------------------------\n",
    "  given question:\n",
    "  {question}\n",
    "  \n",
    "  given sql:\n",
    "  {sql}\n",
    "\n",
    "  given filters:\n",
    "  {filters}\n",
    "  \"\"\"\n",
    "  sql = assetized_query[0]\n",
    "  filters = assetized_query[1]\n",
    "  prompt = prompt_template.format(sql=sql, filters=filters, example_json=example_json, question=question)\n",
    "  response = llm.predict(prompt)\n",
    "  return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_enriched = \"How to check the delay time(second) before shipping for each order and product in this year(2023)?\"\n",
    "\n",
    "response = extract_filter_values(assetized_query, question_enriched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ```json\\n  {\\n    \"parameters\": [\\n      {\\n        \"table_name\": \"bigquery-public-data.thelook_ecommerce.orders\",\\n        \"column\": \"status\",\\n        \"operator\" : \"not in\", \\n        \"type\" : \"STRING\",\\n        \"filter_names\": [\"order_status\"],\\n        \"extracted_values\": [null]\\n      },\\n      {\\n        \"table_name\": \"bigquery-public-data.thelook_ecommerce.orders\",\\n        \"column\": \"created_at\",\\n        \"operator\" : \"between\", \\n        \"type\" : \"TIMESTAMP\",\\n        \"filter_names\": [\"order_created_at_start\", \"order_created_at_end\"],\\n        \"extracted_values\": [\"2023-01-01\", \"2023-12-31\"]\\n      }\\n    ]\\n  }\\n```'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_values = parse_json_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'table_name': 'bigquery-public-data.thelook_ecommerce.orders',\n",
       "  'column': 'status',\n",
       "  'operator': 'not in',\n",
       "  'type': 'STRING',\n",
       "  'filter_names': ['order_status'],\n",
       "  'extracted_values': [None]},\n",
       " {'table_name': 'bigquery-public-data.thelook_ecommerce.orders',\n",
       "  'column': 'created_at',\n",
       "  'operator': 'between',\n",
       "  'type': 'TIMESTAMP',\n",
       "  'filter_names': ['order_created_at_start', 'order_created_at_end'],\n",
       "  'extracted_values': ['2023-01-01', '2023-12-31']}]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_values['parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_unfilled_filters(filter_values):\n",
    "  unfilled_filters = []\n",
    "  for parameter in filter_values['parameters']:\n",
    "    if None in parameter['extracted_values']:\n",
    "      unfilled_filters.append(parameter)\n",
    "  return unfilled_filters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfilled_filters = check_unfilled_filters(filter_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'table_name': 'bigquery-public-data.thelook_ecommerce.orders',\n",
       "  'column': 'status',\n",
       "  'operator': 'not in',\n",
       "  'type': 'STRING',\n",
       "  'filter_names': ['order_status'],\n",
       "  'extracted_values': [None]}]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfilled_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_response_to_fill_filter_values(unfilled_filters, question):\n",
    "  example_json = \"\"\"\n",
    "  {\n",
    "    \"agent_response\": \"...\"\n",
    "  }\n",
    "  \"\"\"\n",
    "  prompt_template = \"\"\"You are an automatic agent to serve natural language to SQL conversion. Please guide the user to fill the missing filter values in the given question and unfilled filters. Output should be the following JSON format.\n",
    "\n",
    "  question:\n",
    "  {question}\n",
    "\n",
    "  unfilled filters:\n",
    "  {unfilled_filters}\n",
    "\n",
    "  output format json:\n",
    "  {example_json}\n",
    "  \"\"\"\n",
    "  prompt = prompt_template.format(unfilled_filters=unfilled_filters, question=question, example_json=example_json)\n",
    "  response = llm.predict(prompt)\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = make_response_to_fill_filter_values(unfilled_filters, question=question_enriched)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' {\\n    \"agent_response\": \"What is the order status that you want to exclude?\"\\n  }'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_response = \"I want to know not cancelled orders only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_filter_values_with_additional_response(unfilled_filters, additional_response):\n",
    "  example_json = \"\"\"\n",
    "  {\n",
    "    \"parameters\": [\n",
    "      {\n",
    "        \"column\": \"col_1\",\n",
    "        \"operator\" : \"in\", \n",
    "        \"type\" : \"STRING\",\n",
    "        \"filter_names\": [\"col_1_filter\"],\n",
    "        \"extracted_values\": [null]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "  \"\"\"\n",
    "\n",
    "  prompt_template = \"\"\"You are a serverside developer. Extract filter values from the user response and unfilled filter information. Do not suggest codes. Output should be the following JSON format.\n",
    "\n",
    "  output format json:\n",
    "  {example_json}\n",
    "\n",
    "  ----------------------------\n",
    "  user response :\n",
    "  {user_response}\n",
    "\n",
    "  unfilled filters:\n",
    "  {unfilled_filters}\n",
    "  \"\"\"\n",
    "  prompt = prompt_template.format(unfilled_filters=unfilled_filters, user_response=additional_response, example_json=example_json)\n",
    "  response = llm.predict(prompt)\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_filter_values = parse_json_response(extract_filter_values_with_additional_response(unfilled_filters, additional_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parameters': [{'column': 'status',\n",
       "   'operator': 'not in',\n",
       "   'type': 'STRING',\n",
       "   'filter_names': ['order_status'],\n",
       "   'extracted_values': ['cancelled']}]}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_filter_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_filter_values(filter_values, additional_filter_values):\n",
    "  original_parameters = filter_values['parameters']\n",
    "  additional_parameters = additional_filter_values['parameters']\n",
    "  for org_parameter in original_parameters:\n",
    "    for add_parameter in additional_parameters:\n",
    "      if org_parameter['column'] == add_parameter['column']:\n",
    "        org_parameter['extracted_values'] = add_parameter['extracted_values']\n",
    "  return filter_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_filter_values = merge_filter_values(filter_values, additional_filter_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parameters': [{'table_name': 'bigquery-public-data.thelook_ecommerce.orders',\n",
       "   'column': 'status',\n",
       "   'operator': 'not in',\n",
       "   'type': 'STRING',\n",
       "   'filter_names': ['order_status'],\n",
       "   'extracted_values': ['cancelled']},\n",
       "  {'table_name': 'bigquery-public-data.thelook_ecommerce.orders',\n",
       "   'column': 'created_at',\n",
       "   'operator': 'between',\n",
       "   'type': 'TIMESTAMP',\n",
       "   'filter_names': ['order_created_at_start', 'order_created_at_end'],\n",
       "   'extracted_values': ['2023-01-01', '2023-12-31']}]}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_filter_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, LLM can handle extraction / tranformation and validation as well. \n",
    "\n",
    "Next step is very similar with 'Direction Conversion'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
