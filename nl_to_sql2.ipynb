{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL to NL to SQL architecture. \n",
    "\n",
    "In many cases, a company has already many anlytic assets such like SQLs, procedure, OLAP cubes and others in their firm. \n",
    "\n",
    "SQL is a valuable tool, but it can be challenging to use in a reusable way because it is not always clear what the query is doing.\n",
    "\n",
    "For example, \n",
    "\n",
    "If someone want to know 'which department has poor performace than the average ?'\n",
    "\n",
    "The goal is very simple, but its implementation SQL is very complex. \n",
    "\n",
    "There is a chasm between the business goal and the specific SQL implentation. \n",
    "\n",
    "In this case, pre-defined complex SQL can help to solve this problem. And we should suggest how to retrieve appropriate SQL from the lots of pre-defined SQLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implment this function\n",
    "import pandas as pd\n",
    "\n",
    "def crawl_prefined_sqls():\n",
    "  sqls = []\n",
    "  # goal = \"SQL to check the delay time(second) before shipping for each order and product\"\n",
    "  sqls.append(\"\"\"\n",
    "CREATE TEMP FUNCTION convertIntervalToSecond(start_ts TIMESTAMP, end_ts TIMESTAMP)\n",
    "RETURNS INT64\n",
    "AS (\n",
    "  (EXTRACT(DAY FROM (end_ts - start_ts)) * 86400 +\n",
    "  EXTRACT(HOUR FROM (end_ts - start_ts)) * 3600 +\n",
    "  EXTRACT(MINUTE FROM (end_ts - start_ts)) * 60 +\n",
    "  EXTRACT(SECOND FROM (end_ts - start_ts)))\n",
    ");\n",
    "select convertIntervalToSecond(a.created_at, a.shipped_at) as order_pending_second, \n",
    "  convertIntervalToSecond(b.created_at, b.shipped_at) as product_pending_second, \n",
    "  a.status, a.order_id, a.user_id, a.gender, a.created_at, a.shipped_at, \n",
    "  b.product_id, b.created_at, b.shipped_at, b.delivered_at, b.returned_at\n",
    " from `bigquery-public-data.thelook_ecommerce.orders` a\n",
    " join `bigquery-public-data.thelook_ecommerce.order_items` b on (a.order_id = b.order_id)\n",
    " where a.status not in ('Cancelled') \n",
    "   and a.created_at between '2022-01-01' and '2022-06-30'\n",
    "order by a.order_id, b.product_id\n",
    "  \"\"\")\n",
    "  return sqls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from langchain.chat_models import ChatVertexAI\n",
    "from langchain.llms import VertexAI\n",
    "import os\n",
    "\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")  # @param {type:\"string\"}\n",
    "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
    "\n",
    "llm_vertex = VertexAI(\n",
    "    #model_name=\"text-bison@latest\",\n",
    "    model_name=\"text-bison-32k\",\n",
    "    max_output_tokens=8000,\n",
    "    temperature=0,\n",
    "    top_p=0.8,\n",
    "    top_k=40,\n",
    ")\n",
    "\n",
    "llm = llm_vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_json_response(llm_json_response) -> any:\n",
    "  #print('llm response:'+ response)\n",
    "  start_char = '['\n",
    "  end_char = ']'\n",
    "  if llm_json_response.find('[') == -1 or max(0,llm_json_response.find('{')) < llm_json_response.find('[') :\n",
    "    start_char = '{'\n",
    "    end_char = '}'\n",
    "  start_index = llm_json_response.find(start_char)\n",
    "  end_index = llm_json_response.rfind(end_char)\n",
    "  json_data = llm_json_response[start_index:end_index+1]\n",
    "  parsed_json = json.loads(json_data)\n",
    "  return parsed_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def parse_python_object(llm_python_object) -> any:\n",
    "  print('llm response:'+ llm_python_object)\n",
    "  if llm_python_object.find('{') == -1:\n",
    "    start_char = '['\n",
    "    end_char = ']'\n",
    "  elif llm_python_object.find('[') == -1 or llm_python_object.find('{') < llm_python_object.find('[') :\n",
    "    start_char = '{'\n",
    "    end_char = '}'\n",
    "  start_index = llm_python_object.find(start_char)\n",
    "  end_index = llm_python_object.rfind(end_char)\n",
    "  object_data = llm_python_object[start_index:end_index+1]\n",
    "  print(object_data)\n",
    "  parsed_object = ast.literal_eval(object_data)\n",
    "  return parsed_object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def explain_sql(sql):\n",
    "  example_json = \"\"\"\n",
    "  {\n",
    "    \"business_goal\": \"explanation of the SQL\",\n",
    "    \"prepared_statement\": \"select convertIntervalToSecond(a.created_at, a.shipped_at) as order_pending_second from sample_table where created_at between ? and ?\",\n",
    "    \"filter_columns\": [\n",
    "      {\n",
    "        \"table_name\": \"sample_table\",\n",
    "        \"column_name\": \"created_at\",\n",
    "        \"business goal\": \"filter by order created date\",\n",
    "        \"operator\": \"between\",\n",
    "        \"column_type\" : \"TIMESTAMP\",\n",
    "        \"filter names\": [\"order_created_at_start\",\"order_created_at_end\"]\n",
    "        \"fitler_order\": 1\n",
    "      }\n",
    "    ],\n",
    "  }\n",
    "  \"\"\"\n",
    "  prompt_template = \"\"\"You are a serverside developer. \n",
    "  Please convert SQL to prepared statement and extract filters from the SQL in a json format. filter_columns include only predicate columns. Do not suggest python code.\n",
    "\n",
    "\n",
    "  target sql:\n",
    "  {sql}\n",
    "\n",
    "  ----------------------------\n",
    "\n",
    "  output format(example): json\n",
    "  {example_json}\n",
    "  \"\"\"\n",
    "  prompt = prompt_template.format(sql=sql, example_json=example_json)\n",
    "  response = llm.predict(prompt)\n",
    "  print(response)\n",
    "  return parse_json_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ```json\n",
      "{\n",
      "    \"business_goal\": \"Get order pending time and product pending time for each order\",\n",
      "    \"prepared_statement\": \"CREATE TEMP FUNCTION convertIntervalToSecond(start_ts TIMESTAMP, end_ts TIMESTAMP)\\nRETURNS INT64\\nAS (\\n  (EXTRACT(DAY FROM (end_ts - start_ts)) * 86400 +\\n  EXTRACT(HOUR FROM (end_ts - start_ts)) * 3600 +\\n  EXTRACT(MINUTE FROM (end_ts - start_ts)) * 60 +\\n  EXTRACT(SECOND FROM (end_ts - start_ts)))\\n);\\nselect convertIntervalToSecond(a.created_at, a.shipped_at) as order_pending_second, \\n  convertIntervalToSecond(b.created_at, b.shipped_at) as product_pending_second, \\n  a.status, a.order_id, a.user_id, a.gender, a.created_at, a.shipped_at, \\n  b.product_id, b.created_at, b.shipped_at, b.delivered_at, b.returned_at\\n from `bigquery-public-data.thelook_ecommerce.orders` a\\n join `bigquery-public-data.thelook_ecommerce.order_items` b on (a.order_id = b.order_id)\\n where a.status not in (?) \\n   and a.created_at between ? and ?\\norder by a.order_id, b.product_id\",\n",
      "    \"filter_columns\": [\n",
      "      {\n",
      "        \"table_name\": \"`bigquery-public-data.thelook_ecommerce.orders`\",\n",
      "        \"column_name\": \"status\",\n",
      "        \"business goal\": \"filter by order status\",\n",
      "        \"operator\": \"not in\",\n",
      "        \"column_type\" : \"STRING\",\n",
      "        \"filter names\": [\"order_status\"],\n",
      "        \"filter_order\": 1\n",
      "      },\n",
      "      {\n",
      "        \"table_name\": \"`bigquery-public-data.thelook_ecommerce.orders`\",\n",
      "        \"column_name\": \"created_at\",\n",
      "        \"business goal\": \"filter by order created date\",\n",
      "        \"operator\": \"between\",\n",
      "        \"column_type\" : \"TIMESTAMP\",\n",
      "        \"filter names\": [\"order_created_at_start\",\"order_created_at_end\"],\n",
      "        \"filter_order\": 2\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "assetized_queries = []\n",
    "\n",
    "## In some cases, the LLM model can't extract the filter columns properly.\n",
    "\n",
    "for sql in crawl_prefined_sqls():\n",
    "  assetized_queries.append(explain_sql(sql))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vector_util import VectorDatabase\n",
    "\n",
    "vdb = VectorDatabase()\n",
    "\n",
    "vdb.truncate_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "\n",
    "embeddings = VertexAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_goal_to_vdb(assetized_queries):\n",
    "  for assetized_query in assetized_queries:\n",
    "    description = assetized_query['business_goal']\n",
    "    sql = assetized_query['prepared_statement']\n",
    "    parameters = assetized_query['filter_columns']\n",
    "    desc_vector = embeddings.embed_query(description)\n",
    "    vdb.insert_record(sql=sql, parameters=parameters, description=description, explore_view=None, model_name=None, table_name=None, column_schema=None, desc_vector=desc_vector)\n",
    "\n",
    "write_goal_to_vdb(assetized_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_query(question):\n",
    "  test_embedding =  embeddings.embed_query(question)\n",
    "  result = None\n",
    "  with vdb.get_connection() as conn:\n",
    "    try:\n",
    "      with conn.cursor() as cur:\n",
    "        select_record = (str(test_embedding).replace(' ',''),)\n",
    "        cur.execute(f\"SELECT sql, parameters, description FROM rag_test where (1 - (desc_vector <=> %s)) > 0.6 limit 1\", select_record)\n",
    "        if cur.rowcount == 0:\n",
    "          return None\n",
    "        rs = cur.fetchone()\n",
    "        result = {\n",
    "          'prepared_statement': rs[0],\n",
    "          'filter_columns': rs[1],\n",
    "          'description': rs[2]\n",
    "        }\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "  return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prepared_statement': 'CREATE TEMP FUNCTION convertIntervalToSecond(start_ts TIMESTAMP, end_ts TIMESTAMP)\\nRETURNS INT64\\nAS (\\n  (EXTRACT(DAY FROM (end_ts - start_ts)) * 86400 +\\n  EXTRACT(HOUR FROM (end_ts - start_ts)) * 3600 +\\n  EXTRACT(MINUTE FROM (end_ts - start_ts)) * 60 +\\n  EXTRACT(SECOND FROM (end_ts - start_ts)))\\n);\\nselect convertIntervalToSecond(a.created_at, a.shipped_at) as order_pending_second, \\n  convertIntervalToSecond(b.created_at, b.shipped_at) as product_pending_second, \\n  a.status, a.order_id, a.user_id, a.gender, a.created_at, a.shipped_at, \\n  b.product_id, b.created_at, b.shipped_at, b.delivered_at, b.returned_at\\n from `bigquery-public-data.thelook_ecommerce.orders` a\\n join `bigquery-public-data.thelook_ecommerce.order_items` b on (a.order_id = b.order_id)\\n where a.status not in (?) \\n   and a.created_at between ? and ?\\norder by a.order_id, b.product_id', 'filter_columns': \"[{'table_name': '`bigquery-public-data.thelook_ecommerce.orders`', 'column_name': 'status', 'business goal': 'filter by order status', 'operator': 'not in', 'column_type': 'STRING', 'filter names': ['order_status'], 'filter_order': 1}, {'table_name': '`bigquery-public-data.thelook_ecommerce.orders`', 'column_name': 'created_at', 'business goal': 'filter by order created date', 'operator': 'between', 'column_type': 'TIMESTAMP', 'filter names': ['order_created_at_start', 'order_created_at_end'], 'filter_order': 2}]\", 'description': 'Get order pending time and product pending time for each order'}\n",
      "{'prepared_statement': 'CREATE TEMP FUNCTION convertIntervalToSecond(start_ts TIMESTAMP, end_ts TIMESTAMP)\\nRETURNS INT64\\nAS (\\n  (EXTRACT(DAY FROM (end_ts - start_ts)) * 86400 +\\n  EXTRACT(HOUR FROM (end_ts - start_ts)) * 3600 +\\n  EXTRACT(MINUTE FROM (end_ts - start_ts)) * 60 +\\n  EXTRACT(SECOND FROM (end_ts - start_ts)))\\n);\\nselect convertIntervalToSecond(a.created_at, a.shipped_at) as order_pending_second, \\n  convertIntervalToSecond(b.created_at, b.shipped_at) as product_pending_second, \\n  a.status, a.order_id, a.user_id, a.gender, a.created_at, a.shipped_at, \\n  b.product_id, b.created_at, b.shipped_at, b.delivered_at, b.returned_at\\n from `bigquery-public-data.thelook_ecommerce.orders` a\\n join `bigquery-public-data.thelook_ecommerce.order_items` b on (a.order_id = b.order_id)\\n where a.status not in (?) \\n   and a.created_at between ? and ?\\norder by a.order_id, b.product_id', 'filter_columns': \"[{'table_name': '`bigquery-public-data.thelook_ecommerce.orders`', 'column_name': 'status', 'business goal': 'filter by order status', 'operator': 'not in', 'column_type': 'STRING', 'filter names': ['order_status'], 'filter_order': 1}, {'table_name': '`bigquery-public-data.thelook_ecommerce.orders`', 'column_name': 'created_at', 'business goal': 'filter by order created date', 'operator': 'between', 'column_type': 'TIMESTAMP', 'filter names': ['order_created_at_start', 'order_created_at_end'], 'filter_order': 2}]\", 'description': 'Get order pending time and product pending time for each order'}\n"
     ]
    }
   ],
   "source": [
    "question = \"How to check the delay time(second) before shipping for each order and product?\"\n",
    "\n",
    "assetized_query = get_related_query(question)\n",
    "print(assetized_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_filter_values(assetized_query, question):\n",
    "  example_json = \"\"\"\n",
    "  {\n",
    "    \"filter_columns\": [\n",
    "      {\n",
    "        \"table_name\": \"sample_table\",\n",
    "        \"column_name\": \"col_1\",\n",
    "        \"operator\" : \"in\", \n",
    "        \"column_type\" : \"STRING\",\n",
    "        \"filter_names\": [\"col_1_filter\"],\n",
    "        \"filter_values\": [null],\n",
    "        \"filter_order\": 1\n",
    "      },\n",
    "      {\n",
    "        \"table_name\": \"sample_table\",\n",
    "        \"column_name\": \"col_2\",\n",
    "        \"operator\" : \"=\", \n",
    "        \"column_type\" : \"STRING\",\n",
    "        \"filter_names\": [\"col_2_filter\"],\n",
    "        \"filter_values\": [\"2022-01\"],\n",
    "        \"filter_order\": 2\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "  \"\"\"\n",
    "\n",
    "  prompt_template = \"\"\"You are a serverside developer. Extract filter values from the question and fill the values into the 'filter_values' item for the given filter columns. Do not suggest codes. Output should be the following JSON format.\n",
    "\n",
    "  given question:\n",
    "  {question}\n",
    "  \n",
    "  given sql:\n",
    "  {sql}\n",
    "\n",
    "  given filters:\n",
    "  {filters}\n",
    "\n",
    "  ----------------------------\n",
    "\n",
    "  output format(example) : json\n",
    "  {example_json}\n",
    "\n",
    "  \"\"\"\n",
    "  sql = assetized_query['prepared_statement']\n",
    "  filters = assetized_query['filter_columns']\n",
    "  prompt = prompt_template.format(sql=sql, filters=filters, example_json=example_json, question=question)\n",
    "  response = llm.predict(prompt)\n",
    "  return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_enriched = \"How to check the delay time(second) before shipping for each order and product in this year(2023)?\"\n",
    "\n",
    "response = extract_filter_values(assetized_query, question_enriched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' {\\n    \"filter_columns\": [\\n      {\\n        \"table_name\": \"`bigquery-public-data.thelook_ecommerce.orders`\",\\n        \"column_name\": \"status\",\\n        \"operator\": \"not in\",\\n        \"column_type\": \"STRING\",\\n        \"filter_names\": [\\n         \"order_status\"\\n        ],\\n        \"filter_values\": [],\\n        \"filter_order\": 1\\n      },\\n      {\\n        \"table_name\": \"`bigquery-public-data.thelook_ecommerce.orders`\",\\n        \"column_name\": \"created_at\",\\n        \"operator\": \"between\",\\n        \"column_type\": \"TIMESTAMP\",\\n        \"filter_names\": [\\n         \"order_created_at_start\",\\n         \"order_created_at_end\"\\n        ],\\n        \"filter_values\": [\\n         \"2023-01-01\",\\n         \"2023-12-31\"\\n        ],\\n        \"filter_order\": 2\\n      }\\n    ]\\n  }'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_values = parse_json_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filter_columns': [{'table_name': '`bigquery-public-data.thelook_ecommerce.orders`',\n",
       "   'column_name': 'status',\n",
       "   'operator': 'not in',\n",
       "   'column_type': 'STRING',\n",
       "   'filter_names': ['order_status'],\n",
       "   'filter_values': [],\n",
       "   'filter_order': 1},\n",
       "  {'table_name': '`bigquery-public-data.thelook_ecommerce.orders`',\n",
       "   'column_name': 'created_at',\n",
       "   'operator': 'between',\n",
       "   'column_type': 'TIMESTAMP',\n",
       "   'filter_names': ['order_created_at_start', 'order_created_at_end'],\n",
       "   'filter_values': ['2023-01-01', '2023-12-31'],\n",
       "   'filter_order': 2}]}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_unfilled_filters(filter_values):\n",
    "  unfilled_filters = []\n",
    "  for parameter in filter_values['filter_columns']:\n",
    "    if None in parameter['filter_values'] or len(parameter['filter_values']) == 0:\n",
    "      unfilled_filters.append(parameter)\n",
    "  return unfilled_filters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfilled_filters = check_unfilled_filters(filter_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'table_name': '`bigquery-public-data.thelook_ecommerce.orders`',\n",
       "  'column_name': 'status',\n",
       "  'operator': 'not in',\n",
       "  'column_type': 'STRING',\n",
       "  'filter_names': ['order_status'],\n",
       "  'filter_values': [],\n",
       "  'filter_order': 1}]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfilled_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_response_to_fill_filter_values(unfilled_filters, question):\n",
    "  example_json = \"\"\"\n",
    "  {\n",
    "    \"agent_response\": \"...\"\n",
    "  }\n",
    "  \"\"\"\n",
    "  prompt_template = \"\"\"You are an automatic agent to serve natural language to SQL conversion. Please guide the user to fill the missing filter values in the given question and unfilled filters. Output should be the following JSON format.\n",
    "\n",
    "  question:\n",
    "  {question}\n",
    "\n",
    "  unfilled filters:\n",
    "  {unfilled_filters}\n",
    "\n",
    "  output format json:\n",
    "  {example_json}\n",
    "  \"\"\"\n",
    "  prompt = prompt_template.format(unfilled_filters=unfilled_filters, question=question, example_json=example_json)\n",
    "  response = llm.predict(prompt)\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = make_response_to_fill_filter_values(unfilled_filters, question=question_enriched)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' {\\n    \"agent_response\": \"What is the order status that you want to exclude?\"\\n  }'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_response = \"I want to know not cancelled orders only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_filter_values_with_additional_response(unfilled_filters, additional_response):\n",
    "  example_json = \"\"\"\n",
    "  {\n",
    "    \"filter_columns\": [\n",
    "      {\n",
    "        \"column_name\": \"col_1\",\n",
    "        \"operator\" : \"in\", \n",
    "        \"column_type\" : \"STRING\",\n",
    "        \"filter_names\": [\"col_1_filter\"],\n",
    "        \"filter_values\": [null]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "  \"\"\"\n",
    "\n",
    "  prompt_template = \"\"\"You are a serverside developer. Extract filter values from the user response and unfilled filter information. Do not suggest codes. Output should be the following JSON format.\n",
    "\n",
    "  output format json:\n",
    "  {example_json}\n",
    "\n",
    "  ----------------------------\n",
    "  user response :\n",
    "  {user_response}\n",
    "\n",
    "  unfilled filters:\n",
    "  {unfilled_filters}\n",
    "  \"\"\"\n",
    "  prompt = prompt_template.format(unfilled_filters=unfilled_filters, user_response=additional_response, example_json=example_json)\n",
    "  response = llm.predict(prompt)\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_filter_values = parse_json_response(extract_filter_values_with_additional_response(unfilled_filters, additional_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filter_columns': [{'column_name': 'status',\n",
       "   'operator': 'not in',\n",
       "   'column_type': 'STRING',\n",
       "   'filter_names': ['order_status'],\n",
       "   'filter_values': ['cancelled']}]}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_filter_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_filter_values(filter_values, additional_filter_values):\n",
    "  original_parameters = filter_values['filter_columns']\n",
    "  additional_parameters = additional_filter_values['filter_columns']\n",
    "  for org_parameter in original_parameters:\n",
    "    for add_parameter in additional_parameters:\n",
    "      if org_parameter['column_name'] == add_parameter['column_name']:\n",
    "        org_parameter['filter_values'] = add_parameter['filter_values']\n",
    "  return filter_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_filter_values = merge_filter_values(filter_values, additional_filter_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filter_columns': [{'table_name': '`bigquery-public-data.thelook_ecommerce.orders`',\n",
       "   'column_name': 'status',\n",
       "   'operator': 'not in',\n",
       "   'column_type': 'STRING',\n",
       "   'filter_names': ['order_status'],\n",
       "   'filter_values': ['cancelled'],\n",
       "   'filter_order': 1},\n",
       "  {'table_name': '`bigquery-public-data.thelook_ecommerce.orders`',\n",
       "   'column_name': 'created_at',\n",
       "   'operator': 'between',\n",
       "   'column_type': 'TIMESTAMP',\n",
       "   'filter_names': ['order_created_at_start', 'order_created_at_end'],\n",
       "   'filter_values': ['2023-01-01', '2023-12-31'],\n",
       "   'filter_order': 2}]}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_filter_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, LLM can handle extraction / tranformation and validation as well. \n",
    "\n",
    "Next step is very similar with 'Direction Conversion'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_field_unique_values(matched_table, matched_field):\n",
    "  if matched_table[0] != '`' :\n",
    "    matched_table = '`' + matched_table + '`'\n",
    "  sql_query = f\"with distinct_values as ( select distinct {matched_field} as {matched_field} from {matched_table} ) select {matched_field}, (select count(1) from distinct_values) as total_count from distinct_values limit 500\"\n",
    "  df = client.query(sql_query).to_dataframe()\n",
    "  return df[matched_field].tolist(), df['total_count'][0]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "def choose_right_filter_value(filter_values, wanted_value):\n",
    "  prompt_template = \"\"\"As a looker developer, choose right filter value for the wanted value below without changing filter value itself.\n",
    "\n",
    "  filter_values : {filter_values}\n",
    "\n",
    "  wanted_values: {wanted_value}\n",
    "\n",
    "  answer format: python list\n",
    "[filter_value1, filter_value2, ...]\n",
    "  \"\"\"\n",
    "  response = llm.predict(prompt_template.format(filter_values=filter_values, wanted_value=wanted_value))\n",
    "  return response \n",
    "\n",
    "def adjust_filter_value(filter_columns):\n",
    "  for filter in filter_columns:\n",
    "    matched_table = filter['table_name']\n",
    "    matched_field = filter['column_name']\n",
    "    filter['unique_values'], filter['unique_count'] = get_field_unique_values(matched_table, matched_field)\n",
    "    # TODO: if unique_count < 500, then choose right filter value in the unique value list.\n",
    "    if filter['unique_count'] < 500:\n",
    "      response = choose_right_filter_value(filter['unique_values'], filter['filter_values'])\n",
    "      if response.strip().find(\"```json\") == 0 :\n",
    "        filter['adjust_filter_values'] = parse_json_response(response)\n",
    "      else:\n",
    "        filter['adjust_filter_values'] = parse_python_object(response)\n",
    "    else:\n",
    "      filter['adjust_filter_values'] = filter['filter_values']\n",
    "    filter['unique_values'] = None\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm response: ```python\n",
      "['Cancelled']\n",
      "```\n",
      "['Cancelled']\n"
     ]
    }
   ],
   "source": [
    "adjust_filter_value(merged_filter_values['filter_columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filter_columns': [{'table_name': '`bigquery-public-data.thelook_ecommerce.orders`',\n",
       "   'column_name': 'status',\n",
       "   'operator': 'not in',\n",
       "   'column_type': 'STRING',\n",
       "   'filter_names': ['order_status'],\n",
       "   'filter_values': ['cancelled'],\n",
       "   'filter_order': 1,\n",
       "   'unique_values': None,\n",
       "   'unique_count': 5,\n",
       "   'adjust_filter_values': ['Cancelled'],\n",
       "   'distinct_values': None},\n",
       "  {'table_name': '`bigquery-public-data.thelook_ecommerce.orders`',\n",
       "   'column_name': 'created_at',\n",
       "   'operator': 'between',\n",
       "   'column_type': 'TIMESTAMP',\n",
       "   'filter_names': ['order_created_at_start', 'order_created_at_end'],\n",
       "   'filter_values': ['2023-01-01', '2023-12-31'],\n",
       "   'filter_order': 2,\n",
       "   'unique_values': None,\n",
       "   'unique_count': 117439,\n",
       "   'adjust_filter_values': ['2023-01-01', '2023-12-31'],\n",
       "   'distinct_values': None}]}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_filter_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepared_statement_with_filter_values_in_bigquery(sql_and_filters):\n",
    "  prepared_statement = sql_and_filters['prepared_statement']\n",
    "  query_parameters = []\n",
    "  for filter_column in sql_and_filters['filter_columns']:\n",
    "    if len(filter_column['adjust_filter_values']) > 1:\n",
    "      if len(filter_column['filter_names']) > 1:\n",
    "        for filter_value in filter_column['adjust_filter_values']:\n",
    "          if(filter_column['column_type'] == 'FLOAT64'):\n",
    "            query_parameters.append(bigquery.ScalarQueryParameter(None, \"FLOAT64\", filter_value))\n",
    "          elif(filter_column['column_type'] == 'INT64'):\n",
    "            query_parameters.append(bigquery.ScalarQueryParameter(None, \"INT64\", filter_value))\n",
    "          else:\n",
    "            query_parameters.append(bigquery.ScalarQueryParameter(None, \"STRING\", filter_value))  \n",
    "      else:\n",
    "        if(filter_column['column_type'] == 'FLOAT64'):\n",
    "          query_parameters.append(bigquery.ArrayQueryParameter(None, \"FLOAT64\", filter_column['adjust_filter_values']))\n",
    "        elif(filter_column['column_type'] == 'INT64'):\n",
    "          query_parameters.append(bigquery.ArrayQueryParameter(None, \"INT64\", filter_column['adjust_filter_values']))\n",
    "        else:\n",
    "          query_parameters.append(bigquery.ArrayQueryParameter(None, \"STRING\", filter_column['adjust_filter_values']))\n",
    "    else:\n",
    "      if(filter_column['column_type'] == 'FLOAT64'):\n",
    "        query_parameters.append(bigquery.ScalarQueryParameter(None, \"FLOAT64\", filter_column['adjust_filter_values'][0]))\n",
    "      elif(filter_column['column_type'] == 'INT64'):\n",
    "        query_parameters.append(bigquery.ScalarQueryParameter(None, \"INT64\", filter_column['adjust_filter_values'][0]))\n",
    "      else:\n",
    "        query_parameters.append(bigquery.ScalarQueryParameter(None, \"STRING\", filter_column['adjust_filter_values'][0]))  \n",
    "  job_config = bigquery.QueryJobConfig(\n",
    "    query_parameters=query_parameters\n",
    "  )\n",
    "  print(query_parameters)\n",
    "  query_job = client.query(prepared_statement, job_config=job_config)\n",
    "  return query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_and_filters = {\n",
    "  'prepared_statement':assetized_query['prepared_statement'],\n",
    "  'filter_columns': merged_filter_values['filter_columns']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prepared_statement': 'CREATE TEMP FUNCTION convertIntervalToSecond(start_ts TIMESTAMP, end_ts TIMESTAMP)\\nRETURNS INT64\\nAS (\\n  (EXTRACT(DAY FROM (end_ts - start_ts)) * 86400 +\\n  EXTRACT(HOUR FROM (end_ts - start_ts)) * 3600 +\\n  EXTRACT(MINUTE FROM (end_ts - start_ts)) * 60 +\\n  EXTRACT(SECOND FROM (end_ts - start_ts)))\\n);\\nselect convertIntervalToSecond(a.created_at, a.shipped_at) as order_pending_second, \\n  convertIntervalToSecond(b.created_at, b.shipped_at) as product_pending_second, \\n  a.status, a.order_id, a.user_id, a.gender, a.created_at, a.shipped_at, \\n  b.product_id, b.created_at, b.shipped_at, b.delivered_at, b.returned_at\\n from `bigquery-public-data.thelook_ecommerce.orders` a\\n join `bigquery-public-data.thelook_ecommerce.order_items` b on (a.order_id = b.order_id)\\n where a.status not in (?) \\n   and a.created_at between ? and ?\\norder by a.order_id, b.product_id',\n",
       " 'filter_columns': [{'table_name': '`bigquery-public-data.thelook_ecommerce.orders`',\n",
       "   'column_name': 'status',\n",
       "   'operator': 'not in',\n",
       "   'column_type': 'STRING',\n",
       "   'filter_names': ['order_status'],\n",
       "   'filter_values': ['cancelled'],\n",
       "   'filter_order': 1,\n",
       "   'unique_values': None,\n",
       "   'unique_count': 5,\n",
       "   'adjust_filter_values': ['Cancelled'],\n",
       "   'distinct_values': None},\n",
       "  {'table_name': '`bigquery-public-data.thelook_ecommerce.orders`',\n",
       "   'column_name': 'created_at',\n",
       "   'operator': 'between',\n",
       "   'column_type': 'TIMESTAMP',\n",
       "   'filter_names': ['order_created_at_start', 'order_created_at_end'],\n",
       "   'filter_values': ['2023-01-01', '2023-12-31'],\n",
       "   'filter_order': 2,\n",
       "   'unique_values': None,\n",
       "   'unique_count': 117439,\n",
       "   'adjust_filter_values': ['2023-01-01', '2023-12-31'],\n",
       "   'distinct_values': None}]}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_and_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ScalarQueryParameter(None, 'STRING', 'Cancelled'), ScalarQueryParameter(None, 'STRING', '2023-01-01'), ScalarQueryParameter(None, 'STRING', '2023-12-31')]\n"
     ]
    }
   ],
   "source": [
    "df_result = prepared_statement_with_filter_values_in_bigquery(sql_and_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_pending_second</th>\n",
       "      <th>product_pending_second</th>\n",
       "      <th>status</th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>created_at</th>\n",
       "      <th>shipped_at</th>\n",
       "      <th>product_id</th>\n",
       "      <th>created_at_1</th>\n",
       "      <th>shipped_at_1</th>\n",
       "      <th>delivered_at</th>\n",
       "      <th>returned_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2520</td>\n",
       "      <td>15675</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>2023-02-20 12:34:00+00:00</td>\n",
       "      <td>2023-02-20 13:16:00+00:00</td>\n",
       "      <td>13848</td>\n",
       "      <td>2023-02-20 08:54:45+00:00</td>\n",
       "      <td>2023-02-20 13:16:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210660</td>\n",
       "      <td>217579</td>\n",
       "      <td>Returned</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>F</td>\n",
       "      <td>2023-11-06 16:57:00+00:00</td>\n",
       "      <td>2023-11-09 03:28:00+00:00</td>\n",
       "      <td>3735</td>\n",
       "      <td>2023-11-06 15:01:41+00:00</td>\n",
       "      <td>2023-11-09 03:28:00+00:00</td>\n",
       "      <td>2023-11-10 00:43:00+00:00</td>\n",
       "      <td>2023-11-11 01:32:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76020</td>\n",
       "      <td>82580</td>\n",
       "      <td>Complete</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>M</td>\n",
       "      <td>2023-11-24 10:44:00+00:00</td>\n",
       "      <td>2023-11-25 07:51:00+00:00</td>\n",
       "      <td>28363</td>\n",
       "      <td>2023-11-24 08:54:40+00:00</td>\n",
       "      <td>2023-11-25 07:51:00+00:00</td>\n",
       "      <td>2023-11-25 23:11:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Processing</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>M</td>\n",
       "      <td>2023-07-10 10:44:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>24678</td>\n",
       "      <td>2023-07-10 07:46:42+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66480</td>\n",
       "      <td>72788</td>\n",
       "      <td>Complete</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>M</td>\n",
       "      <td>2023-05-04 10:44:00+00:00</td>\n",
       "      <td>2023-05-05 05:12:00+00:00</td>\n",
       "      <td>18588</td>\n",
       "      <td>2023-05-04 08:58:52+00:00</td>\n",
       "      <td>2023-05-05 05:12:00+00:00</td>\n",
       "      <td>2023-05-07 03:48:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>66480</td>\n",
       "      <td>-14648</td>\n",
       "      <td>Complete</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>M</td>\n",
       "      <td>2023-05-04 10:44:00+00:00</td>\n",
       "      <td>2023-05-05 05:12:00+00:00</td>\n",
       "      <td>27795</td>\n",
       "      <td>2023-05-05 09:16:08+00:00</td>\n",
       "      <td>2023-05-05 05:12:00+00:00</td>\n",
       "      <td>2023-05-07 03:48:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Processing</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>M</td>\n",
       "      <td>2023-08-24 10:44:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>16479</td>\n",
       "      <td>2023-08-24 10:00:36+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Processing</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>F</td>\n",
       "      <td>2023-01-07 14:21:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>6282</td>\n",
       "      <td>2023-01-08 12:54:13+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Processing</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>F</td>\n",
       "      <td>2023-01-07 14:21:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>6972</td>\n",
       "      <td>2023-01-11 13:44:11+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>146640</td>\n",
       "      <td>160028</td>\n",
       "      <td>Complete</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>F</td>\n",
       "      <td>2023-08-01 08:45:00+00:00</td>\n",
       "      <td>2023-08-03 01:29:00+00:00</td>\n",
       "      <td>9652</td>\n",
       "      <td>2023-08-01 05:01:52+00:00</td>\n",
       "      <td>2023-08-03 01:29:00+00:00</td>\n",
       "      <td>2023-08-04 23:30:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_pending_second  product_pending_second      status  order_id  \\\n",
       "0                  2520                   15675     Shipped         2   \n",
       "1                210660                  217579    Returned         5   \n",
       "2                 76020                   82580    Complete         6   \n",
       "3                  <NA>                    <NA>  Processing         7   \n",
       "4                 66480                   72788    Complete         8   \n",
       "5                 66480                  -14648    Complete         8   \n",
       "6                  <NA>                    <NA>  Processing         9   \n",
       "7                  <NA>                    <NA>  Processing        10   \n",
       "8                  <NA>                    <NA>  Processing        10   \n",
       "9                146640                  160028    Complete        11   \n",
       "\n",
       "   user_id gender                created_at                shipped_at  \\\n",
       "0        3      F 2023-02-20 12:34:00+00:00 2023-02-20 13:16:00+00:00   \n",
       "1        6      F 2023-11-06 16:57:00+00:00 2023-11-09 03:28:00+00:00   \n",
       "2        7      M 2023-11-24 10:44:00+00:00 2023-11-25 07:51:00+00:00   \n",
       "3        7      M 2023-07-10 10:44:00+00:00                       NaT   \n",
       "4        7      M 2023-05-04 10:44:00+00:00 2023-05-05 05:12:00+00:00   \n",
       "5        7      M 2023-05-04 10:44:00+00:00 2023-05-05 05:12:00+00:00   \n",
       "6        7      M 2023-08-24 10:44:00+00:00                       NaT   \n",
       "7        8      F 2023-01-07 14:21:00+00:00                       NaT   \n",
       "8        8      F 2023-01-07 14:21:00+00:00                       NaT   \n",
       "9        9      F 2023-08-01 08:45:00+00:00 2023-08-03 01:29:00+00:00   \n",
       "\n",
       "   product_id              created_at_1              shipped_at_1  \\\n",
       "0       13848 2023-02-20 08:54:45+00:00 2023-02-20 13:16:00+00:00   \n",
       "1        3735 2023-11-06 15:01:41+00:00 2023-11-09 03:28:00+00:00   \n",
       "2       28363 2023-11-24 08:54:40+00:00 2023-11-25 07:51:00+00:00   \n",
       "3       24678 2023-07-10 07:46:42+00:00                       NaT   \n",
       "4       18588 2023-05-04 08:58:52+00:00 2023-05-05 05:12:00+00:00   \n",
       "5       27795 2023-05-05 09:16:08+00:00 2023-05-05 05:12:00+00:00   \n",
       "6       16479 2023-08-24 10:00:36+00:00                       NaT   \n",
       "7        6282 2023-01-08 12:54:13+00:00                       NaT   \n",
       "8        6972 2023-01-11 13:44:11+00:00                       NaT   \n",
       "9        9652 2023-08-01 05:01:52+00:00 2023-08-03 01:29:00+00:00   \n",
       "\n",
       "               delivered_at               returned_at  \n",
       "0                       NaT                       NaT  \n",
       "1 2023-11-10 00:43:00+00:00 2023-11-11 01:32:00+00:00  \n",
       "2 2023-11-25 23:11:00+00:00                       NaT  \n",
       "3                       NaT                       NaT  \n",
       "4 2023-05-07 03:48:00+00:00                       NaT  \n",
       "5 2023-05-07 03:48:00+00:00                       NaT  \n",
       "6                       NaT                       NaT  \n",
       "7                       NaT                       NaT  \n",
       "8                       NaT                       NaT  \n",
       "9 2023-08-04 23:30:00+00:00                       NaT  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
