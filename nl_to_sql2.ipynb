{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL to NL to SQL architecture. \n",
    "\n",
    "In many cases, a company has already many anlytic assets such like SQLs, procedure, OLAP cubes and others in their firm. \n",
    "\n",
    "SQL is a valuable tool, but it can be challenging to use in a reusable way because it is not always clear what the query is doing.\n",
    "\n",
    "For example, \n",
    "\n",
    "If someone want to know 'which department has poor performace than the average ?'\n",
    "\n",
    "The goal is very simple, but its implementation SQL is very complex. \n",
    "\n",
    "There is a chasm between the business goal and the specific SQL implentation. \n",
    "\n",
    "In this case, pre-defined complex SQL can help to solve this problem. And we should suggest how to retrieve appropriate SQL from the lots of pre-defined SQLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pandas google-cloud-aiplatform google-cloud-bigquery\n",
    "#! pip install python-dotenv langchain\n",
    "#! pip install langchain-google-vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implment this function\n",
    "import pandas as pd\n",
    "\n",
    "def crawl_prefined_sqls():\n",
    "  sqls = []\n",
    "  # goal = \"SQL to check the delay time(second) before shipping for each order and product\"\n",
    "  sqls.append(\"\"\"\n",
    "CREATE TEMP FUNCTION convertIntervalToSecond(start_ts TIMESTAMP, end_ts TIMESTAMP)\n",
    "RETURNS INT64\n",
    "AS (\n",
    "  (EXTRACT(DAY FROM (end_ts - start_ts)) * 86400 +\n",
    "  EXTRACT(HOUR FROM (end_ts - start_ts)) * 3600 +\n",
    "  EXTRACT(MINUTE FROM (end_ts - start_ts)) * 60 +\n",
    "  EXTRACT(SECOND FROM (end_ts - start_ts)))\n",
    ");\n",
    "select convertIntervalToSecond(a.created_at, a.shipped_at) as order_pending_second, \n",
    "  convertIntervalToSecond(b.created_at, b.shipped_at) as product_pending_second, \n",
    "  a.status, a.order_id, a.user_id, a.gender, a.created_at, a.shipped_at, \n",
    "  b.product_id, b.created_at, b.shipped_at, b.delivered_at, b.returned_at\n",
    " from `bigquery-public-data.thelook_ecommerce.orders` a\n",
    " join `bigquery-public-data.thelook_ecommerce.order_items` b on (a.order_id = b.order_id)\n",
    " where a.status not in ('Cancelled') \n",
    "   and a.created_at between '2022-01-01' and '2022-06-30'\n",
    "order by a.order_id, b.product_id\n",
    "  \"\"\")\n",
    "  return sqls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from langchain.chat_models import ChatVertexAI\n",
    "from langchain_google_vertexai import VertexAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PROJECT_ID=os.getenv(\"PROJECT_ID\")  # @param {type:\"string\"}\n",
    "LOCATION=os.getenv(\"LOCATION\")\n",
    "DATASET=os.getenv(\"DATASET\")\n",
    "TABLE_NAME=os.getenv(\"TABLE_NAME\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
    "\n",
    "llm_vertex = VertexAI(\n",
    "    #model_name=\"text-bison@latest\",\n",
    "    model_name=\"text-bison-32k@002\",\n",
    "    max_output_tokens=8000,\n",
    "    temperature=0,\n",
    "    top_p=0.8,\n",
    "    top_k=40,\n",
    ")\n",
    "\n",
    "llm = llm_vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "def parse_json_response(llm_json_response) -> any:\n",
    "  #print('llm response:'+ response)\n",
    "  start_char = '['\n",
    "  end_char = ']'\n",
    "  if llm_json_response.find('[') == -1 or max(0,llm_json_response.find('{')) < llm_json_response.find('[') :\n",
    "    start_char = '{'\n",
    "    end_char = '}'\n",
    "  start_index = llm_json_response.find(start_char)\n",
    "  end_index = llm_json_response.rfind(end_char)\n",
    "  json_data = llm_json_response[start_index:end_index+1]\n",
    "  parsed_json = json.loads(json_data)\n",
    "  return parsed_json\n",
    "\n",
    "def parse_python_object(llm_python_object) -> any:\n",
    "  print('llm response:'+ llm_python_object)\n",
    "  if llm_python_object.find('{') == -1:\n",
    "    start_char = '['\n",
    "    end_char = ']'\n",
    "  elif llm_python_object.find('[') == -1 or llm_python_object.find('{') < llm_python_object.find('[') :\n",
    "    start_char = '{'\n",
    "    end_char = '}'\n",
    "  start_index = llm_python_object.find(start_char)\n",
    "  end_index = llm_python_object.rfind(end_char)\n",
    "  object_data = llm_python_object[start_index:end_index+1]\n",
    "  print(object_data)\n",
    "  parsed_object = ast.literal_eval(object_data)\n",
    "  return parsed_object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def explain_sql(sql):\n",
    "  example_json = \"\"\"\n",
    "  {\n",
    "    \"business_goal\": \"explanation of the SQL\",\n",
    "    \"prepared_statement\": \"select ... from .... where created_at between ? and ?\", // A prepared statement that is exactly the same as the given SQL which can include Temporary function, except for parameter substitution.\n",
    "    \"filter_columns\": [\n",
    "      {\n",
    "        \"table_name\": \"project_id(optional).dataset_name.sample_table\",\n",
    "        \"column_name\": \"created_at\",\n",
    "        \"business goal\": \"filter by order created date\",\n",
    "        \"operator\": \"between\",\n",
    "        \"column_type\" : \"TIMESTAMP\",\n",
    "        \"filter names\": [\"order_created_at_start\",\"order_created_at_end\"]\n",
    "        \"fitler_order\": 1\n",
    "      }\n",
    "    ],\n",
    "  }\n",
    "  \"\"\"\n",
    "  prompt_template = \"\"\"You are a server-side developer.\n",
    "Please convert the provided SQL to a prepared_statement and extract the filters from the SQL in JSON format. The filter_columns should only include predicate columns. Do not suggest Python code. Describe the business goal based on the prepared_statement.\n",
    "Step 1: Convert the provided SQL to a prepared_statement.\n",
    "Step 2: Extract the filters from the SQL in JSON format. The filter_columns should only include predicate columns. Do not suggest Python code.\n",
    "Step 3: Describe the business goal based on the prepared_statement.\n",
    "\n",
    "----------------------------\n",
    "example sql :\n",
    "select convertIntervalToSecond(a.created_at, a.shipped_at) as order_pending_second from sample_table where created_at between '2023-01-01' and '2023-12-01'\n",
    "\n",
    "example output json:\n",
    "{example_json}\n",
    "\n",
    "----------------------------\n",
    "provided sql:\n",
    "{sql}\n",
    "\n",
    "output json:\n",
    "\"\"\"\n",
    "  prompt = prompt_template.format(sql=sql, example_json=example_json)\n",
    "  response = llm.invoke(prompt)\n",
    "  print(response)\n",
    "  return parse_json_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ```json\n",
      "{\n",
      "  \"business_goal\": \"This query aims to analyze order and product-related metrics for orders placed between January 1, 2022, and June 30, 2022, excluding canceled orders.\",\n",
      "  \"prepared_statement\": \"CREATE TEMP FUNCTION convertIntervalToSecond(start_ts TIMESTAMP, end_ts TIMESTAMP) RETURNS INT64 AS ((EXTRACT(DAY FROM (end_ts - start_ts)) * 86400 + EXTRACT(HOUR FROM (end_ts - start_ts)) * 3600 + EXTRACT(MINUTE FROM (end_ts - start_ts)) * 60 + EXTRACT(SECOND FROM (end_ts - start_ts))));\\nselect convertIntervalToSecond(a.created_at, a.shipped_at) as order_pending_second, convertIntervalToSecond(b.created_at, b.shipped_at) as product_pending_second, a.status, a.order_id, a.user_id, a.gender, a.created_at, a.shipped_at, b.product_id, b.created_at, b.shipped_at, b.delivered_at, b.returned_at from `bigquery-public-data.thelook_ecommerce.orders` a join `bigquery-public-data.thelook_ecommerce.order_items` b on (a.order_id = b.order_id) where a.status not in (?) and a.created_at between ? and ? order by a.order_id, b.product_id\",\n",
      "  \"filter_columns\": [\n",
      "    {\n",
      "      \"table_name\": \"bigquery-public-data.thelook_ecommerce.orders\",\n",
      "      \"column_name\": \"status\",\n",
      "      \"business goal\": \"Exclude canceled orders\",\n",
      "      \"operator\": \"not in\",\n",
      "      \"column_type\" : \"STRING\",\n",
      "      \"filter names\": [\"order_status\"],\n",
      "      \"filter_order\": 1\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"bigquery-public-data.thelook_ecommerce.orders\",\n",
      "      \"column_name\": \"created_at\",\n",
      "      \"business goal\": \"Filter orders placed between January 1, 2022, and June 30, 2022\",\n",
      "      \"operator\": \"between\",\n",
      "      \"column_type\" : \"TIMESTAMP\",\n",
      "      \"filter names\": [\"order_created_at_start\",\"order_created_at_end\"],\n",
      "      \"filter_order\": 2\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "assetized_queries = []\n",
    "\n",
    "## In some cases, the LLM model can't extract the filter columns properly.\n",
    "\n",
    "for sql in crawl_prefined_sqls():\n",
    "  assetized_queries.append(explain_sql(sql))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "QueryJob<project=turnkey-charter-358922, location=asia-northeast3, id=69db7b1d-9bf5-463c-8577-c4cd42f080fa>\n"
     ]
    }
   ],
   "source": [
    "# from vector_util import VectorDatabase\n",
    "\n",
    "# vdb = VectorDatabase()\n",
    "\n",
    "# vdb.truncate_table()\n",
    "\n",
    "from bigquery_vector_util import BigQueryVectorDatabase, SqlSearchSchema\n",
    "\n",
    "vdb = BigQueryVectorDatabase(project_id=PROJECT_ID, location=LOCATION, dataset=DATASET, table_name=TABLE_NAME)\n",
    "vdb.create_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "embdding_model = VertexAIEmbeddings(\"textembedding-gecko-multilingual@latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "def write_goal_to_vdb(assetized_queries):\n",
    "  records = []\n",
    "  for assetized_query in assetized_queries:\n",
    "    description = assetized_query['business_goal']\n",
    "    sql = assetized_query['prepared_statement']\n",
    "    parameters = json.dumps(assetized_query['filter_columns'])\n",
    "    desc_vector = embdding_model.embed_query(description)\n",
    "    records.append(SqlSearchSchema(sql=sql, description=description, desc_vector=desc_vector, parameters=parameters, explore_view=None, model_name=None, table_name=None, column_schema=None))\n",
    "  vdb.insert_record(records)\n",
    "\n",
    "write_goal_to_vdb(assetized_queries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Stage\n",
    "\n",
    "After to ingest predefined SQls into Vector Database, we need to retrieve them in a right way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "def parse_json_response(llm_json_response) -> any:\n",
    "  #print('llm response:'+ response)\n",
    "  start_char = '['\n",
    "  end_char = ']'\n",
    "  if llm_json_response.find('[') == -1 or max(0,llm_json_response.find('{')) < llm_json_response.find('[') :\n",
    "    start_char = '{'\n",
    "    end_char = '}'\n",
    "  start_index = llm_json_response.find(start_char)\n",
    "  end_index = llm_json_response.rfind(end_char)\n",
    "  json_data = llm_json_response[start_index:end_index+1]\n",
    "  parsed_json = json.loads(json_data)\n",
    "  return parsed_json\n",
    "\n",
    "def parse_python_object(llm_python_object) -> any:\n",
    "  print('llm response:'+ llm_python_object)\n",
    "  if llm_python_object.find('{') == -1:\n",
    "    start_char = '['\n",
    "    end_char = ']'\n",
    "  elif llm_python_object.find('[') == -1 or llm_python_object.find('{') < llm_python_object.find('[') :\n",
    "    start_char = '{'\n",
    "    end_char = '}'\n",
    "  start_index = llm_python_object.find(start_char)\n",
    "  end_index = llm_python_object.rfind(end_char)\n",
    "  object_data = llm_python_object[start_index:end_index+1]\n",
    "  print(object_data)\n",
    "  parsed_object = ast.literal_eval(object_data)\n",
    "  return parsed_object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from langchain.chat_models import ChatVertexAI\n",
    "from langchain_google_vertexai import VertexAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PROJECT_ID=os.getenv(\"PROJECT_ID\")  # @param {type:\"string\"}\n",
    "LOCATION=os.getenv(\"LOCATION\")\n",
    "DATASET=os.getenv(\"DATASET\")\n",
    "TABLE_NAME=os.getenv(\"TABLE_NAME\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
    "\n",
    "llm_vertex = VertexAI(\n",
    "    #model_name=\"text-bison@latest\",\n",
    "    model_name=\"text-bison-32k@002\",\n",
    "    max_output_tokens=8000,\n",
    "    temperature=0,\n",
    "    top_p=0.8,\n",
    "    top_k=40,\n",
    ")\n",
    "\n",
    "llm = llm_vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "embedding_model = VertexAIEmbeddings(\"textembedding-gecko-multilingual@latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigquery_vector_util import BigQueryVectorDatabase, SqlSearchSchema\n",
    "\n",
    "vdb = BigQueryVectorDatabase(project_id=PROJECT_ID, location=LOCATION, dataset=DATASET, table_name=TABLE_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_query(question):\n",
    "  test_embedding =  embedding_model.embed_query(question)\n",
    "  related_queries = vdb.select_similar_query(test_embedding)\n",
    "  result = None\n",
    "  if related_queries is not None:\n",
    "    result = { \n",
    "      \"uuid\" : related_queries['uuid'][0],\n",
    "      \"sql\" : related_queries['sql'][0],\n",
    "      \"description\" : related_queries['description'][0],\n",
    "      \"parameters\" : related_queries['parameters'][0],\n",
    "      \"explore_view\" : related_queries['explore_view'][0],\n",
    "      \"model_name\" : related_queries['model_name'][0],\n",
    "      \"table_name\" : related_queries['table_name'][0],\n",
    "      \"column_schema\" : related_queries['column_schema'][0],\n",
    "      \"distance\" : related_queries['distance'][0]\n",
    "    }\n",
    "  else:\n",
    "    result = { \n",
    "      \"uuid\" : \"\",\n",
    "      \"sql\" : \"\",\n",
    "      \"description\" : \"\",\n",
    "      \"parameters\" : \"\",\n",
    "      \"explore_view\" : \"\",\n",
    "      \"model_name\" : \"\",\n",
    "      \"table_name\" : \"\",\n",
    "      \"column_schema\" : \"\",\n",
    "      \"distance\" : 1\n",
    "    }\n",
    "  return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uuid': 'f98d0e64-03ae-4cb0-9e80-137ba594f697', 'sql': 'CREATE TEMP FUNCTION convertIntervalToSecond(start_ts TIMESTAMP, end_ts TIMESTAMP) RETURNS INT64 AS ((EXTRACT(DAY FROM (end_ts - start_ts)) * 86400 + EXTRACT(HOUR FROM (end_ts - start_ts)) * 3600 + EXTRACT(MINUTE FROM (end_ts - start_ts)) * 60 + EXTRACT(SECOND FROM (end_ts - start_ts))));\\nselect convertIntervalToSecond(a.created_at, a.shipped_at) as order_pending_second, convertIntervalToSecond(b.created_at, b.shipped_at) as product_pending_second, a.status, a.order_id, a.user_id, a.gender, a.created_at, a.shipped_at, b.product_id, b.created_at, b.shipped_at, b.delivered_at, b.returned_at from `bigquery-public-data.thelook_ecommerce.orders` a join `bigquery-public-data.thelook_ecommerce.order_items` b on (a.order_id = b.order_id) where a.status not in (?) and a.created_at between ? and ? order by a.order_id, b.product_id', 'description': 'This query aims to analyze order and product-related metrics for orders placed between January 1, 2022, and June 30, 2022, excluding canceled orders.', 'parameters': '[{\"table_name\": \"bigquery-public-data.thelook_ecommerce.orders\", \"column_name\": \"status\", \"business goal\": \"Exclude canceled orders\", \"operator\": \"not in\", \"column_type\": \"STRING\", \"filter names\": [\"order_status\"], \"filter_order\": 1}, {\"table_name\": \"bigquery-public-data.thelook_ecommerce.orders\", \"column_name\": \"created_at\", \"business goal\": \"Filter orders placed between January 1, 2022, and June 30, 2022\", \"operator\": \"between\", \"column_type\": \"TIMESTAMP\", \"filter names\": [\"order_created_at_start\", \"order_created_at_end\"], \"filter_order\": 2}]', 'explore_view': None, 'model_name': None, 'table_name': None, 'column_schema': None, 'distance': 0.8118540877372782}\n"
     ]
    }
   ],
   "source": [
    "question = \"How to check the delay time(second) before shipping for each order and product?\"\n",
    "\n",
    "assetized_query = get_related_query(question)\n",
    "print(assetized_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_filter_values(assetized_query, question):\n",
    "  example_json = \"\"\"\n",
    "  {\n",
    "    \"filter_columns\": [\n",
    "      {\n",
    "        \"table_name\": \"sample_table\",\n",
    "        \"column_name\": \"col_1\",\n",
    "        \"operator\" : \"in\", \n",
    "        \"column_type\" : \"STRING\",\n",
    "        \"filter_names\": [\"col_1_filter\"],\n",
    "        \"filter_values\": [null],\n",
    "        \"filter_order\": 1\n",
    "      },\n",
    "      {\n",
    "        \"table_name\": \"sample_table\",\n",
    "        \"column_name\": \"col_2\",\n",
    "        \"operator\" : \"=\", \n",
    "        \"column_type\" : \"STRING\",\n",
    "        \"filter_names\": [\"col_2_filter\"],\n",
    "        \"filter_values\": [\"2022-01\"],\n",
    "        \"filter_order\": 2\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "  \"\"\"\n",
    "\n",
    "  prompt_template = \"\"\"You are a serverside developer. Extract filter values from the question and fill the values into the 'filter_values' item for the given filter columns. Do not suggest codes. Output should be the following JSON format.\n",
    "\n",
    "  given question:\n",
    "  {question}\n",
    "  \n",
    "  given sql:\n",
    "  {sql}\n",
    "\n",
    "  given filters:\n",
    "  {filters}\n",
    "\n",
    "  ----------------------------\n",
    "\n",
    "  output format(example) : json\n",
    "  {example_json}\n",
    "\n",
    "  \"\"\"\n",
    "  sql = assetized_query['sql']\n",
    "  filters = assetized_query['parameters']\n",
    "  prompt = prompt_template.format(sql=sql, filters=filters, example_json=example_json, question=question)\n",
    "  response = llm.invoke(prompt)\n",
    "  return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_enriched = \"How to check the delay time(second) before shipping for each order and product in this year(2023)?\"\n",
    "\n",
    "response = extract_filter_values(assetized_query, question_enriched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' {\\n    \"filter_columns\": [\\n      {\\n        \"table_name\": \"bigquery-public-data.thelook_ecommerce.orders\",\\n        \"column_name\": \"status\",\\n        \"operator\": \"not in\",\\n        \"column_type\": \"STRING\",\\n        \"filter_names\": [\"order_status\"],\\n        \"filter_values\": [\"canceled\"],\\n        \"filter_order\": 1\\n      },\\n      {\\n        \"table_name\": \"bigquery-public-data.thelook_ecommerce.orders\",\\n        \"column_name\": \"created_at\",\\n        \"operator\": \"between\",\\n        \"column_type\": \"TIMESTAMP\",\\n        \"filter_names\": [\"order_created_at_start\", \"order_created_at_end\"],\\n        \"filter_values\": [\"2023-01-01\", \"2023-12-31\"],\\n        \"filter_order\": 2\\n      }\\n    ]\\n  }'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_values = parse_json_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filter_columns': [{'table_name': 'bigquery-public-data.thelook_ecommerce.orders',\n",
       "   'column_name': 'status',\n",
       "   'operator': 'not in',\n",
       "   'column_type': 'STRING',\n",
       "   'filter_names': ['order_status'],\n",
       "   'filter_values': ['canceled'],\n",
       "   'filter_order': 1},\n",
       "  {'table_name': 'bigquery-public-data.thelook_ecommerce.orders',\n",
       "   'column_name': 'created_at',\n",
       "   'operator': 'between',\n",
       "   'column_type': 'TIMESTAMP',\n",
       "   'filter_names': ['order_created_at_start', 'order_created_at_end'],\n",
       "   'filter_values': ['2023-01-01', '2023-12-31'],\n",
       "   'filter_order': 2}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_unfilled_filters(filter_values):\n",
    "  unfilled_filters = []\n",
    "  for parameter in filter_values['filter_columns']:\n",
    "    if None in parameter['filter_values'] or len(parameter['filter_values']) == 0:\n",
    "      unfilled_filters.append(parameter)\n",
    "  return unfilled_filters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfilled_filters = check_unfilled_filters(filter_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfilled_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_response_to_fill_filter_values(unfilled_filters, question):\n",
    "  example_json = \"\"\"\n",
    "  {\n",
    "    \"agent_response\": \"...\"\n",
    "  }\n",
    "  \"\"\"\n",
    "  prompt_template = \"\"\"You are an automatic agent to serve natural language to SQL conversion. Please guide the user to fill the missing filter values in the given question and unfilled filters. Output should be the following JSON format.\n",
    "\n",
    "  question:\n",
    "  {question}\n",
    "\n",
    "  unfilled filters:\n",
    "  {unfilled_filters}\n",
    "\n",
    "  output format json:\n",
    "  {example_json}\n",
    "  \"\"\"\n",
    "  prompt = prompt_template.format(unfilled_filters=unfilled_filters, question=question, example_json=example_json)\n",
    "  response = llm.predict(prompt)\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/postgres/devel/looker_palm_integration/.venv/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "response = make_response_to_fill_filter_values(unfilled_filters, question=question_enriched)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' {\\n    \"agent_response\": \"To check the delay time (in seconds) before shipping for each order and product in the year 2023, you can use the following SQL query:\\\\n\\\\n```sql\\\\nSELECT \\\\n    o.order_id, \\\\n    p.product_id, \\\\n    o.order_date, \\\\n    o.ship_date, \\\\n    JULIANDAY(o.ship_date) - JULIANDAY(o.order_date) AS delay_in_days,\\\\n    (JULIANDAY(o.ship_date) - JULIANDAY(o.order_date))*24*60*60 AS delay_in_seconds\\\\nFROM \\\\n    orders AS o\\\\nJOIN \\\\n    products AS p ON o.product_id = p.product_id\\\\nWHERE \\\\n    o.order_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\\\\n```\\\\n\\\\nThis query will give you the order ID, product ID, order date, ship date, delay in days, and delay in seconds for all orders and products in the year 2023.\"\\n  }'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_response = \"I want to know not cancelled orders only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_filter_values_with_additional_response(unfilled_filters, additional_response):\n",
    "  example_json = \"\"\"\n",
    "  {\n",
    "    \"filter_columns\": [\n",
    "      {\n",
    "        \"column_name\": \"col_1\",\n",
    "        \"operator\" : \"in\", \n",
    "        \"column_type\" : \"STRING\",\n",
    "        \"filter_names\": [\"col_1_filter\"],\n",
    "        \"filter_values\": [null]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "  \"\"\"\n",
    "\n",
    "  prompt_template = \"\"\"You are a serverside developer. Extract filter values from the user response and unfilled filter information. Do not suggest codes. Output should be the following JSON format.\n",
    "\n",
    "  output format json:\n",
    "  {example_json}\n",
    "\n",
    "  ----------------------------\n",
    "  user response :\n",
    "  {user_response}\n",
    "\n",
    "  unfilled filters:\n",
    "  {unfilled_filters}\n",
    "  \"\"\"\n",
    "  prompt = prompt_template.format(unfilled_filters=unfilled_filters, user_response=additional_response, example_json=example_json)\n",
    "  response = llm.predict(prompt)\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_filter_values = parse_json_response(extract_filter_values_with_additional_response(unfilled_filters, additional_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filter_columns': [{'column_name': 'status',\n",
       "   'operator': 'not in',\n",
       "   'column_type': 'STRING',\n",
       "   'filter_names': ['status_filter'],\n",
       "   'filter_values': ['cancelled']}]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_filter_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_filter_values(filter_values, additional_filter_values):\n",
    "  original_parameters = filter_values['filter_columns']\n",
    "  additional_parameters = additional_filter_values['filter_columns']\n",
    "  for org_parameter in original_parameters:\n",
    "    for add_parameter in additional_parameters:\n",
    "      if org_parameter['column_name'] == add_parameter['column_name']:\n",
    "        org_parameter['filter_values'] = add_parameter['filter_values']\n",
    "  return filter_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_filter_values = merge_filter_values(filter_values, additional_filter_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filter_columns': [{'table_name': 'bigquery-public-data.thelook_ecommerce.orders',\n",
       "   'column_name': 'status',\n",
       "   'operator': 'not in',\n",
       "   'column_type': 'STRING',\n",
       "   'filter_names': ['order_status'],\n",
       "   'filter_values': ['cancelled'],\n",
       "   'filter_order': 1},\n",
       "  {'table_name': 'bigquery-public-data.thelook_ecommerce.orders',\n",
       "   'column_name': 'created_at',\n",
       "   'operator': 'between',\n",
       "   'column_type': 'TIMESTAMP',\n",
       "   'filter_names': ['order_created_at_start', 'order_created_at_end'],\n",
       "   'filter_values': ['2023-01-01', '2023-12-31'],\n",
       "   'filter_order': 2}]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_filter_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, LLM can handle extraction / tranformation and validation as well. \n",
    "\n",
    "Next step is very similar with 'Direction Conversion'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_field_unique_values(matched_table, matched_field):\n",
    "  if matched_table[0] != '`' :\n",
    "    matched_table = '`' + matched_table + '`'\n",
    "  sql_query = f\"with distinct_values as ( select distinct {matched_field} as {matched_field} from {matched_table} ) select {matched_field}, (select count(1) from distinct_values) as total_count from distinct_values limit 500\"\n",
    "  df = client.query(sql_query).to_dataframe()\n",
    "  return df[matched_field].tolist(), df['total_count'][0]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "def choose_right_filter_value(filter_values, wanted_value):\n",
    "  prompt_template = \"\"\"As a looker developer, choose right filter value for the wanted value below without changing filter value itself.\n",
    "\n",
    "  filter_values : {filter_values}\n",
    "\n",
    "  wanted_values: {wanted_value}\n",
    "\n",
    "  answer format: python list\n",
    "[filter_value1, filter_value2, ...]\n",
    "  \"\"\"\n",
    "  response = llm.predict(prompt_template.format(filter_values=filter_values, wanted_value=wanted_value))\n",
    "  return response \n",
    "\n",
    "def adjust_filter_value(filter_columns):\n",
    "  for filter in filter_columns:\n",
    "    matched_table = filter['table_name']\n",
    "    matched_field = filter['column_name']\n",
    "    filter['unique_values'], filter['unique_count'] = get_field_unique_values(matched_table, matched_field)\n",
    "    # TODO: if unique_count < 500, then choose right filter value in the unique value list.\n",
    "    if filter['unique_count'] < 500:\n",
    "      response = choose_right_filter_value(filter['unique_values'], filter['filter_values'])\n",
    "      if response.strip().find(\"```json\") == 0 :\n",
    "        filter['adjust_filter_values'] = parse_json_response(response)\n",
    "      else:\n",
    "        filter['adjust_filter_values'] = parse_python_object(response)\n",
    "    else:\n",
    "      filter['adjust_filter_values'] = filter['filter_values']\n",
    "    filter['unique_values'] = None\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm response: ```python\n",
      "['Cancelled']\n",
      "```\n",
      "['Cancelled']\n"
     ]
    }
   ],
   "source": [
    "adjust_filter_value(merged_filter_values['filter_columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filter_columns': [{'table_name': 'bigquery-public-data.thelook_ecommerce.orders',\n",
       "   'column_name': 'status',\n",
       "   'operator': 'not in',\n",
       "   'column_type': 'STRING',\n",
       "   'filter_names': ['order_status'],\n",
       "   'filter_values': ['cancelled'],\n",
       "   'filter_order': 1,\n",
       "   'unique_values': None,\n",
       "   'unique_count': 5,\n",
       "   'adjust_filter_values': ['Cancelled']},\n",
       "  {'table_name': 'bigquery-public-data.thelook_ecommerce.orders',\n",
       "   'column_name': 'created_at',\n",
       "   'operator': 'between',\n",
       "   'column_type': 'TIMESTAMP',\n",
       "   'filter_names': ['order_created_at_start', 'order_created_at_end'],\n",
       "   'filter_values': ['2023-01-01', '2023-12-31'],\n",
       "   'filter_order': 2,\n",
       "   'unique_values': None,\n",
       "   'unique_count': 117304,\n",
       "   'adjust_filter_values': ['2023-01-01', '2023-12-31']}]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_filter_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepared_statement_with_filter_values_in_bigquery(sql_and_filters):\n",
    "  prepared_statement = sql_and_filters['prepared_statement']\n",
    "  query_parameters = []\n",
    "  for filter_column in sql_and_filters['filter_columns']:\n",
    "    if len(filter_column['adjust_filter_values']) > 1:\n",
    "      if len(filter_column['filter_names']) > 1:\n",
    "        for filter_value in filter_column['adjust_filter_values']:\n",
    "          if(filter_column['column_type'] == 'FLOAT64'):\n",
    "            query_parameters.append(bigquery.ScalarQueryParameter(None, \"FLOAT64\", filter_value))\n",
    "          elif(filter_column['column_type'] == 'INT64'):\n",
    "            query_parameters.append(bigquery.ScalarQueryParameter(None, \"INT64\", filter_value))\n",
    "          else:\n",
    "            query_parameters.append(bigquery.ScalarQueryParameter(None, \"STRING\", filter_value))  \n",
    "      else:\n",
    "        if(filter_column['column_type'] == 'FLOAT64'):\n",
    "          query_parameters.append(bigquery.ArrayQueryParameter(None, \"FLOAT64\", filter_column['adjust_filter_values']))\n",
    "        elif(filter_column['column_type'] == 'INT64'):\n",
    "          query_parameters.append(bigquery.ArrayQueryParameter(None, \"INT64\", filter_column['adjust_filter_values']))\n",
    "        else:\n",
    "          query_parameters.append(bigquery.ArrayQueryParameter(None, \"STRING\", filter_column['adjust_filter_values']))\n",
    "    else:\n",
    "      if(filter_column['column_type'] == 'FLOAT64'):\n",
    "        query_parameters.append(bigquery.ScalarQueryParameter(None, \"FLOAT64\", filter_column['adjust_filter_values'][0]))\n",
    "      elif(filter_column['column_type'] == 'INT64'):\n",
    "        query_parameters.append(bigquery.ScalarQueryParameter(None, \"INT64\", filter_column['adjust_filter_values'][0]))\n",
    "      else:\n",
    "        query_parameters.append(bigquery.ScalarQueryParameter(None, \"STRING\", filter_column['adjust_filter_values'][0]))  \n",
    "  job_config = bigquery.QueryJobConfig(\n",
    "    query_parameters=query_parameters\n",
    "  )\n",
    "  print(query_parameters)\n",
    "  query_job = client.query(prepared_statement, job_config=job_config)\n",
    "  return query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_and_filters = {\n",
    "  'prepared_statement':assetized_query['sql'],\n",
    "  'filter_columns': merged_filter_values['filter_columns']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prepared_statement': 'CREATE TEMP FUNCTION convertIntervalToSecond(start_ts TIMESTAMP, end_ts TIMESTAMP) RETURNS INT64 AS ((EXTRACT(DAY FROM (end_ts - start_ts)) * 86400 + EXTRACT(HOUR FROM (end_ts - start_ts)) * 3600 + EXTRACT(MINUTE FROM (end_ts - start_ts)) * 60 + EXTRACT(SECOND FROM (end_ts - start_ts))));\\nselect convertIntervalToSecond(a.created_at, a.shipped_at) as order_pending_second, convertIntervalToSecond(b.created_at, b.shipped_at) as product_pending_second, a.status, a.order_id, a.user_id, a.gender, a.created_at, a.shipped_at, b.product_id, b.created_at, b.shipped_at, b.delivered_at, b.returned_at from `bigquery-public-data.thelook_ecommerce.orders` a join `bigquery-public-data.thelook_ecommerce.order_items` b on (a.order_id = b.order_id) where a.status not in (?) and a.created_at between ? and ? order by a.order_id, b.product_id',\n",
       " 'filter_columns': [{'table_name': 'bigquery-public-data.thelook_ecommerce.orders',\n",
       "   'column_name': 'status',\n",
       "   'operator': 'not in',\n",
       "   'column_type': 'STRING',\n",
       "   'filter_names': ['order_status'],\n",
       "   'filter_values': ['cancelled'],\n",
       "   'filter_order': 1,\n",
       "   'unique_values': None,\n",
       "   'unique_count': 5,\n",
       "   'adjust_filter_values': ['Cancelled']},\n",
       "  {'table_name': 'bigquery-public-data.thelook_ecommerce.orders',\n",
       "   'column_name': 'created_at',\n",
       "   'operator': 'between',\n",
       "   'column_type': 'TIMESTAMP',\n",
       "   'filter_names': ['order_created_at_start', 'order_created_at_end'],\n",
       "   'filter_values': ['2023-01-01', '2023-12-31'],\n",
       "   'filter_order': 2,\n",
       "   'unique_values': None,\n",
       "   'unique_count': 117304,\n",
       "   'adjust_filter_values': ['2023-01-01', '2023-12-31']}]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_and_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ScalarQueryParameter(None, 'STRING', 'Cancelled'), ScalarQueryParameter(None, 'STRING', '2023-01-01'), ScalarQueryParameter(None, 'STRING', '2023-12-31')]\n"
     ]
    }
   ],
   "source": [
    "df_result = prepared_statement_with_filter_values_in_bigquery(sql_and_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_pending_second</th>\n",
       "      <th>product_pending_second</th>\n",
       "      <th>status</th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>created_at</th>\n",
       "      <th>shipped_at</th>\n",
       "      <th>product_id</th>\n",
       "      <th>created_at_1</th>\n",
       "      <th>shipped_at_1</th>\n",
       "      <th>delivered_at</th>\n",
       "      <th>returned_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197100</td>\n",
       "      <td>206241</td>\n",
       "      <td>Complete</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>2023-06-26 08:14:00+00:00</td>\n",
       "      <td>2023-06-28 14:59:00+00:00</td>\n",
       "      <td>1076</td>\n",
       "      <td>2023-06-26 05:41:39+00:00</td>\n",
       "      <td>2023-06-28 14:59:00+00:00</td>\n",
       "      <td>2023-07-03 00:40:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180480</td>\n",
       "      <td>193555</td>\n",
       "      <td>Complete</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>2023-02-19 12:58:00+00:00</td>\n",
       "      <td>2023-02-21 15:06:00+00:00</td>\n",
       "      <td>5061</td>\n",
       "      <td>2023-02-19 09:20:05+00:00</td>\n",
       "      <td>2023-02-21 15:06:00+00:00</td>\n",
       "      <td>2023-02-22 12:23:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115320</td>\n",
       "      <td>122997</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>2023-07-21 16:57:00+00:00</td>\n",
       "      <td>2023-07-23 00:59:00+00:00</td>\n",
       "      <td>16024</td>\n",
       "      <td>2023-07-21 14:49:03+00:00</td>\n",
       "      <td>2023-07-23 00:59:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115320</td>\n",
       "      <td>-54714</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>2023-07-21 16:57:00+00:00</td>\n",
       "      <td>2023-07-23 00:59:00+00:00</td>\n",
       "      <td>24282</td>\n",
       "      <td>2023-07-23 16:10:54+00:00</td>\n",
       "      <td>2023-07-23 00:59:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Processing</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>2023-11-02 07:48:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>16206</td>\n",
       "      <td>2023-11-02 07:01:41+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>222000</td>\n",
       "      <td>231890</td>\n",
       "      <td>Complete</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>2023-12-25 18:53:00+00:00</td>\n",
       "      <td>2023-12-28 08:33:00+00:00</td>\n",
       "      <td>9250</td>\n",
       "      <td>2023-12-25 16:08:10+00:00</td>\n",
       "      <td>2023-12-28 08:33:00+00:00</td>\n",
       "      <td>2024-01-02 07:16:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38280</td>\n",
       "      <td>-213306</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>M</td>\n",
       "      <td>2023-09-22 05:39:00+00:00</td>\n",
       "      <td>2023-09-22 16:17:00+00:00</td>\n",
       "      <td>17894</td>\n",
       "      <td>2023-09-25 03:32:06+00:00</td>\n",
       "      <td>2023-09-22 16:17:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38280</td>\n",
       "      <td>40113</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>M</td>\n",
       "      <td>2023-09-22 05:39:00+00:00</td>\n",
       "      <td>2023-09-22 16:17:00+00:00</td>\n",
       "      <td>20063</td>\n",
       "      <td>2023-09-22 05:08:27+00:00</td>\n",
       "      <td>2023-09-22 16:17:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>137640</td>\n",
       "      <td>63251</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>F</td>\n",
       "      <td>2023-12-07 04:42:00+00:00</td>\n",
       "      <td>2023-12-08 18:56:00+00:00</td>\n",
       "      <td>394</td>\n",
       "      <td>2023-12-08 01:21:49+00:00</td>\n",
       "      <td>2023-12-08 18:56:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>137640</td>\n",
       "      <td>137431</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>F</td>\n",
       "      <td>2023-12-07 04:42:00+00:00</td>\n",
       "      <td>2023-12-08 18:56:00+00:00</td>\n",
       "      <td>7272</td>\n",
       "      <td>2023-12-07 04:45:29+00:00</td>\n",
       "      <td>2023-12-08 18:56:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_pending_second  product_pending_second      status  order_id  \\\n",
       "0                197100                  206241    Complete         1   \n",
       "1                180480                  193555    Complete         3   \n",
       "2                115320                  122997     Shipped         5   \n",
       "3                115320                  -54714     Shipped         5   \n",
       "4                  <NA>                    <NA>  Processing         6   \n",
       "5                222000                  231890    Complete         7   \n",
       "6                 38280                 -213306     Shipped         9   \n",
       "7                 38280                   40113     Shipped         9   \n",
       "8                137640                   63251     Shipped        12   \n",
       "9                137640                  137431     Shipped        12   \n",
       "\n",
       "   user_id gender                created_at                shipped_at  \\\n",
       "0        1      F 2023-06-26 08:14:00+00:00 2023-06-28 14:59:00+00:00   \n",
       "1        2      F 2023-02-19 12:58:00+00:00 2023-02-21 15:06:00+00:00   \n",
       "2        3      M 2023-07-21 16:57:00+00:00 2023-07-23 00:59:00+00:00   \n",
       "3        3      M 2023-07-21 16:57:00+00:00 2023-07-23 00:59:00+00:00   \n",
       "4        4      M 2023-11-02 07:48:00+00:00                       NaT   \n",
       "5        5      F 2023-12-25 18:53:00+00:00 2023-12-28 08:33:00+00:00   \n",
       "6        6      M 2023-09-22 05:39:00+00:00 2023-09-22 16:17:00+00:00   \n",
       "7        6      M 2023-09-22 05:39:00+00:00 2023-09-22 16:17:00+00:00   \n",
       "8        7      F 2023-12-07 04:42:00+00:00 2023-12-08 18:56:00+00:00   \n",
       "9        7      F 2023-12-07 04:42:00+00:00 2023-12-08 18:56:00+00:00   \n",
       "\n",
       "   product_id              created_at_1              shipped_at_1  \\\n",
       "0        1076 2023-06-26 05:41:39+00:00 2023-06-28 14:59:00+00:00   \n",
       "1        5061 2023-02-19 09:20:05+00:00 2023-02-21 15:06:00+00:00   \n",
       "2       16024 2023-07-21 14:49:03+00:00 2023-07-23 00:59:00+00:00   \n",
       "3       24282 2023-07-23 16:10:54+00:00 2023-07-23 00:59:00+00:00   \n",
       "4       16206 2023-11-02 07:01:41+00:00                       NaT   \n",
       "5        9250 2023-12-25 16:08:10+00:00 2023-12-28 08:33:00+00:00   \n",
       "6       17894 2023-09-25 03:32:06+00:00 2023-09-22 16:17:00+00:00   \n",
       "7       20063 2023-09-22 05:08:27+00:00 2023-09-22 16:17:00+00:00   \n",
       "8         394 2023-12-08 01:21:49+00:00 2023-12-08 18:56:00+00:00   \n",
       "9        7272 2023-12-07 04:45:29+00:00 2023-12-08 18:56:00+00:00   \n",
       "\n",
       "               delivered_at returned_at  \n",
       "0 2023-07-03 00:40:00+00:00         NaT  \n",
       "1 2023-02-22 12:23:00+00:00         NaT  \n",
       "2                       NaT         NaT  \n",
       "3                       NaT         NaT  \n",
       "4                       NaT         NaT  \n",
       "5 2024-01-02 07:16:00+00:00         NaT  \n",
       "6                       NaT         NaT  \n",
       "7                       NaT         NaT  \n",
       "8                       NaT         NaT  \n",
       "9                       NaT         NaT  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
